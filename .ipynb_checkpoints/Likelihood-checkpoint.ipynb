{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5222a752-373c-4f71-888e-9566c163ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import gc\n",
    "import warnings\n",
    "import time\n",
    "import csv\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd89bec-2976-4b97-8f1a-d433fedb76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "import pylandau\n",
    "from pylandau import langau\n",
    "from importlib import reload\n",
    "from scipy.optimize import curve_fit, fsolve\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92db160b-a045-480c-8cb5-78a1513c7be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpv</th>\n",
       "      <th>eta</th>\n",
       "      <th>sigma</th>\n",
       "      <th>A</th>\n",
       "      <th>e_min</th>\n",
       "      <th>e_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.803007</td>\n",
       "      <td>0.093791</td>\n",
       "      <td>0.119056</td>\n",
       "      <td>46997.004267</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>0.775131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.798057</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.119167</td>\n",
       "      <td>47823.332739</td>\n",
       "      <td>0.775131</td>\n",
       "      <td>1.051753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.802907</td>\n",
       "      <td>0.088229</td>\n",
       "      <td>0.119790</td>\n",
       "      <td>48442.106488</td>\n",
       "      <td>1.051753</td>\n",
       "      <td>1.329333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.815841</td>\n",
       "      <td>0.090575</td>\n",
       "      <td>0.118259</td>\n",
       "      <td>47281.687815</td>\n",
       "      <td>1.329333</td>\n",
       "      <td>1.616180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.827044</td>\n",
       "      <td>0.089453</td>\n",
       "      <td>0.119206</td>\n",
       "      <td>46258.901199</td>\n",
       "      <td>1.616180</td>\n",
       "      <td>1.922888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.840702</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.123704</td>\n",
       "      <td>46919.792355</td>\n",
       "      <td>1.922888</td>\n",
       "      <td>2.261627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.846874</td>\n",
       "      <td>0.089786</td>\n",
       "      <td>0.119922</td>\n",
       "      <td>46861.289391</td>\n",
       "      <td>2.261627</td>\n",
       "      <td>2.633586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.858266</td>\n",
       "      <td>0.091372</td>\n",
       "      <td>0.124476</td>\n",
       "      <td>45887.131602</td>\n",
       "      <td>2.633586</td>\n",
       "      <td>3.050361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.861948</td>\n",
       "      <td>0.090268</td>\n",
       "      <td>0.120616</td>\n",
       "      <td>46809.408420</td>\n",
       "      <td>3.050361</td>\n",
       "      <td>3.529028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.869164</td>\n",
       "      <td>0.091751</td>\n",
       "      <td>0.122918</td>\n",
       "      <td>45821.256348</td>\n",
       "      <td>3.529028</td>\n",
       "      <td>4.081656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.876786</td>\n",
       "      <td>0.090615</td>\n",
       "      <td>0.121369</td>\n",
       "      <td>46494.390491</td>\n",
       "      <td>4.081656</td>\n",
       "      <td>4.740676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.881881</td>\n",
       "      <td>0.090458</td>\n",
       "      <td>0.119407</td>\n",
       "      <td>46764.645638</td>\n",
       "      <td>4.740676</td>\n",
       "      <td>5.456240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.883957</td>\n",
       "      <td>0.091348</td>\n",
       "      <td>0.120434</td>\n",
       "      <td>45959.032408</td>\n",
       "      <td>5.456240</td>\n",
       "      <td>6.341753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.889486</td>\n",
       "      <td>0.090973</td>\n",
       "      <td>0.121862</td>\n",
       "      <td>45700.559017</td>\n",
       "      <td>6.341753</td>\n",
       "      <td>7.499147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.898036</td>\n",
       "      <td>0.091728</td>\n",
       "      <td>0.119749</td>\n",
       "      <td>45674.877455</td>\n",
       "      <td>7.499147</td>\n",
       "      <td>8.917898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.900250</td>\n",
       "      <td>0.088760</td>\n",
       "      <td>0.122747</td>\n",
       "      <td>46271.109357</td>\n",
       "      <td>8.917898</td>\n",
       "      <td>11.036604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.904201</td>\n",
       "      <td>0.091790</td>\n",
       "      <td>0.117428</td>\n",
       "      <td>46350.292790</td>\n",
       "      <td>11.036604</td>\n",
       "      <td>14.126374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.910225</td>\n",
       "      <td>0.091351</td>\n",
       "      <td>0.121919</td>\n",
       "      <td>45590.555429</td>\n",
       "      <td>14.126374</td>\n",
       "      <td>19.276368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.910225</td>\n",
       "      <td>0.092482</td>\n",
       "      <td>0.118356</td>\n",
       "      <td>45797.713453</td>\n",
       "      <td>19.276368</td>\n",
       "      <td>30.691736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.913697</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.122219</td>\n",
       "      <td>46016.570444</td>\n",
       "      <td>30.691736</td>\n",
       "      <td>99.727712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mpv       eta     sigma             A      e_min      e_max\n",
       "0   1.803007  0.093791  0.119056  46997.004267   0.100015   0.775131\n",
       "1   1.798057  0.089401  0.119167  47823.332739   0.775131   1.051753\n",
       "2   1.802907  0.088229  0.119790  48442.106488   1.051753   1.329333\n",
       "3   1.815841  0.090575  0.118259  47281.687815   1.329333   1.616180\n",
       "4   1.827044  0.089453  0.119206  46258.901199   1.616180   1.922888\n",
       "5   1.840702  0.088889  0.123704  46919.792355   1.922888   2.261627\n",
       "6   1.846874  0.089786  0.119922  46861.289391   2.261627   2.633586\n",
       "7   1.858266  0.091372  0.124476  45887.131602   2.633586   3.050361\n",
       "8   1.861948  0.090268  0.120616  46809.408420   3.050361   3.529028\n",
       "9   1.869164  0.091751  0.122918  45821.256348   3.529028   4.081656\n",
       "10  1.876786  0.090615  0.121369  46494.390491   4.081656   4.740676\n",
       "11  1.881881  0.090458  0.119407  46764.645638   4.740676   5.456240\n",
       "12  1.883957  0.091348  0.120434  45959.032408   5.456240   6.341753\n",
       "13  1.889486  0.090973  0.121862  45700.559017   6.341753   7.499147\n",
       "14  1.898036  0.091728  0.119749  45674.877455   7.499147   8.917898\n",
       "15  1.900250  0.088760  0.122747  46271.109357   8.917898  11.036604\n",
       "16  1.904201  0.091790  0.117428  46350.292790  11.036604  14.126374\n",
       "17  1.910225  0.091351  0.121919  45590.555429  14.126374  19.276368\n",
       "18  1.910225  0.092482  0.118356  45797.713453  19.276368  30.691736\n",
       "19  1.913697  0.089305  0.122219  46016.570444  30.691736  99.727712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit_data_loc = r'./data/stat_fit_data_full.csv'\n",
    "# fit_data_loc = r'./data/fit_data_full.csv'\n",
    "fitdata = pd.read_csv(fit_data_loc)\n",
    "display(fitdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edeb65-55b3-47b4-a465-d944843daf05",
   "metadata": {},
   "source": [
    "This fixes an issue with the <code>pylandau.langau_pdf</code> function normalization. I redefine my own langau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd4f685-b530-4375-b69c-29295254f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langau_pdf(dedx, mpv, eta, sig):\n",
    "    return eta * pylandau.get_langau_pdf(dedx, mpv, eta, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c89f3e6e-f902-4e90-8085-a6a8faf77723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Loaded!\n",
      "Sorting into array of muons...\n",
      "Done!\n",
      "Removed 5661 muons.\n"
     ]
    }
   ],
   "source": [
    "import cer_util\n",
    "cer = cer_util.CER()\n",
    "cer.load_muons()\n",
    "cer.slim_muons() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefaca02-9fc3-486d-97d4-0d2bf5374459",
   "metadata": {},
   "source": [
    "The likelihood will only depend on the dedxs and the landau fit parameters. The true energies are calculated for reference. For a given dedx ($x_i$) the probability that it corresponds to a measurement from energy bin $j$ is given by:\n",
    "$$p_j(x_i)=\\frac{f_j(x_i)}{\\sum_{k}f_k(x_i)}$$\n",
    "where $f_j$ is the langau pdf associated with energy bin $j$ and the denominator is the sum of the langau pdfs at $x_i$ over all energy bins. **Assuming the $x_i$ are independent (which is wrong)**, the likelihood that all the data $x_i$ correspond to energy bin $j$ is:\n",
    "$$\\mathscr{L}_j=\\prod_i\\frac{f_j(x_i)}{\\sum_k f_k(x_i)}$$\n",
    "We use the log-likelihood:\n",
    "$$\\log\\mathscr{L}_j=\\sum_i\\left[\\log f_j(x_i)-\\log \\sum_k f_k(x_i)\\right]$$\n",
    "This uses an incorrect assumption that the $x_i$ are all independent. In principle, the $x_i$ should follow the Bethe-Bloch curve as each subsequent $x_i$ corresponds to an energy loss from a muon of slightly lower kinetic energy. Corrections for this effect will be implemented later. Then the matter of maximizing the likelihood is akin to selecting energy bin $j$ with the highest $\\mathscr{L}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76d290d4-7660-4a47-b448-452aa0f63c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def like_max(dedxs):\n",
    "    landau_params = np.array([ fitdata.iloc[i][:3] for i in range(fitdata.shape[0]) ])\n",
    "    \n",
    "    # One big list comprehension for maximum calculation speed\n",
    "    loglike = np.array([ np.sum([ np.log(langau_pdf(xi, *fj_params)) - np.log(np.sum([ langau_pdf(xi, *fk_params) for fk_params in landau_params])) for xi in dedxs ]) for fj_params in landau_params])\n",
    "    \n",
    "    jtilde = np.argmax(loglike)\n",
    "    e_min_tilde, e_max_tilde = fitdata.iloc[jtilde,-2:]\n",
    "    return e_min_tilde, e_max_tilde, loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8265ce6b-c1e2-4ab1-bd0f-b2ffa9152bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_e(muon):  \n",
    "    es, dedxs = cer.generate_eloss(muon)\n",
    "    e_min_tilde, e_max_tilde, loglike = like_max(dedxs)\n",
    "    return e_min_tilde, e_max_tilde, loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b715b958-e931-48fc-a08e-a64fd8eb2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(cer_util)\n",
    "cer = cer_util.CER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dbb8b405-78d6-4d52-9b35-97956a182439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating elosses and reconstructing energy...\n",
      "Done! Analysis time: 2m 25.8s\n"
     ]
    }
   ],
   "source": [
    "truth = []\n",
    "reconstructed = []\n",
    "loglikes = []\n",
    "p_count = 0\n",
    "\n",
    "tot_particles = len(muons)\n",
    "pcnt_per_count = 100./tot_particles\n",
    "count_per_pcnt = 1/pcnt_per_count\n",
    "running_count_for_pcnt_increment = 0\n",
    "\n",
    "print(\"Generating elosses and reconstructing energy...\")\n",
    "start = time.perf_counter()\n",
    "for muon in muons:\n",
    "    if p_count > running_count_for_pcnt_increment:\n",
    "        print(f\"{(running_count_for_pcnt_increment / tot_particles)*100:.0f}%   \", end = '\\r', flush=True)\n",
    "        running_count_for_pcnt_increment += count_per_pcnt\n",
    "        \n",
    "    p_count += 1\n",
    "    e_min, e_max, loglike = reconstruct_e(muon)\n",
    "    \n",
    "    true_e = muon['backtracked_e']\n",
    "    truth.append(true_e)\n",
    "    \n",
    "    guess_e = (e_min, e_max)\n",
    "    reconstructed.append(guess_e)\n",
    "    loglikes.append(loglike)\n",
    "    \n",
    "end = time.perf_counter()\n",
    "t = end-start\n",
    "print(f\"Done! Analysis time: {int(t//60)}m {t%60:0.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5d085cdc-622a-42d6-b393-e013c5f0e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_data_dict = []\n",
    "for i in range(len(truth)):\n",
    "    t = truth[i]\n",
    "    re_min = reconstructed[i][0]\n",
    "    re_max = reconstructed[i][1]\n",
    "    \n",
    "    this_dict = {'truth': t, 'reconstructed_min': re_min, 'reconstructed_max': re_max}\n",
    "    \n",
    "    for j in range(len(loglikes[i])):\n",
    "        like = loglikes[i][j]\n",
    "        this_dict[f'L{j}'] = like\n",
    "    \n",
    "    like_data_dict.append(this_dict)\n",
    "    \n",
    "like_data = pd.DataFrame.from_dict(like_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e929b-ef6b-4d3d-b726-1247ba7af88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_data.to_csv(r'./data/stat_binned_likelihood_data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6753897-55e6-4ac0-aec6-ede3d709078d",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Obviously, this likelihood is pretty much useless, although there are further things to do to hopefully make it work better.\n",
    "     - Could langau fits binned by statistics, rather than binned logarithmically. The likelihood can be sensitive to uncertainties, so having each bin have the same statistics might fix this. This is borne out by the fact that the likelihood\n",
    "     - Could implement an improved likelihood function, which accounts for the loss of energy each step, although I am not quite sure how to do this.\n",
    "     - Adding another dimension to the likelihood in the form of the pitch may also help to fix this, although this is a large project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5d18e07-3f82-4570-b171-4bd8f3c39063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "200\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(truth)):\n",
    "    t = truth[i]\n",
    "    r = reconstructed[i]\n",
    "    if t > r[0] and t < r[1]:\n",
    "        correct += 1\n",
    "print(correct)\n",
    "print(len(truth))\n",
    "print(correct/len(truth)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ab3e1fa3-9177-4a62-8975-82099f6ff7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = zip(*reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2de91e9e-6b98-4c9b-8b34-795c473718d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loglikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80753d60-e8fe-427b-b3f5-9f223fdf6307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
