{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import gc\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "import csv\n",
    "from util.theory import deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data location: ./data/simulated_cosmics.root:CalorimetryAnalyzer\n"
     ]
    }
   ],
   "source": [
    "full = False\n",
    "\n",
    "if full:\n",
    "    data_loc = r\"./data/simulated_cosmics_full.root:nuselection/CalorimetryAnalyzer\"\n",
    "else:\n",
    "    data_loc = r\"./data/simulated_cosmics.root:CalorimetryAnalyzer\"\n",
    "print(\"Using data location:\", data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# Don't import ROOT unless absolutely necessary (takes a long time)\n",
    "# import ROOT\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = uproot.open(data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_particle_variables = ['backtracked_e','backtracked_pdg','backtracked_purity']\n",
    "variables = ['dedx_y','rr_y','pitch_y']\n",
    "slimmer_variables = ['trk_sce_start_x','trk_sce_start_y','trk_sce_start_z', 'trk_sce_end_x','trk_sce_end_y','trk_sce_end_z','backtracked_e', 'backtracked_pdg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag for removal\n",
    "The following cell populates the list <code>idxs_to_remove</code>, tagging the relevant rows of the dataframe for removal. For now, removal criterion is based solely on whether we think the particle both enters and exits the detector. If it neither enters nor exits at a boundary, particle is tagged for removal.\n",
    "- TODO: Speed this up using jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate principal dataframe and slim\n",
    "In the future, we will want to do this in batches, as even the slimmed data will be too large to hold in memory all at once. Here, the data is loaded to memory in its entirety, and then slimmed accordingly. Even if we slim better, there is no way around loading the data entirely first before slimming (at least, not that I know of, uproot documentation seems to suggest no - there may be a way in  raw C++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Slimming Mask...\n",
      "Will remove 3431 particles\n"
     ]
    }
   ],
   "source": [
    "def distance_to_edge(r):\n",
    "    dimensions = np.array([[0, 256], [-116,116], [0,1036]])\n",
    "    return  np.min(np.abs(dimensions - r[:, np.newaxis]))\n",
    "\n",
    "print(\"Preparing Slimming Mask...\")\n",
    "slimmerdf = tree.arrays(slimmer_variables, library='pd')\n",
    "\n",
    "start_dists, end_dists = np.array([ [distance_to_edge(r[:3]), distance_to_edge(r[3:6])] for _, r in slimmerdf.iterrows() ]).T\n",
    "energy_mask = (slimmerdf.backtracked_e > 1) & (slimmerdf.backtracked_e < 10) & (np.abs(slimmerdf.backtracked_pdg) == 13)\n",
    "mask = ((start_dists < 2) & (end_dists < 2) & energy_mask).to_numpy()\n",
    "print(\"Will remove\", np.sum(~mask), \"particles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Principal Dataframe...\n",
      "Loaded dedx_y data...\n",
      "1828660\n",
      "Loaded rr_y data...\n",
      "Loaded pitch_y data...\n",
      "Generated!\n",
      "Original Size: 45.395421 MB\n",
      "Slimmed Size: 19.694047 MB\n"
     ]
    }
   ],
   "source": [
    "# Generate DataFrame with the data\n",
    "# There seems to be a memory leak in pandas https://github.com/pandas-dev/pandas/issues/2659. This casues the \n",
    "# allocated memory for the dataframe to be much higher than required. As of now there is no simple fix that I \n",
    "# can find, so I will have to work around it.\n",
    "# Maybe look into this further later if it is a problem with the larger dataset.\n",
    "\n",
    "print(\"Generating Principal Dataframe...\")\n",
    "part_df = tree.arrays(per_particle_variables, library='pd')\n",
    "df = tree.arrays(variables[0], library='pd')\n",
    "print(\"Loaded\", variables[0], \"data...\")\n",
    "size = sys.getsizeof(df)\n",
    "\n",
    "# Slim according to mask\n",
    "part_df = part_df.loc[mask]\n",
    "mask = mask[df.index.get_level_values(0)] # Broadcast to multiindex shape\n",
    "print(len(mask))\n",
    "df = df.loc[mask, :]\n",
    "\n",
    "# This loop loads in the next column of the dataframe, slims it, and appends it to df\n",
    "for name in variables[1:]:\n",
    "    next_col = tree.arrays(name, library='pd')\n",
    "    print(\"Loaded\", name, \"data...\")\n",
    "    size += sys.getsizeof(next_col[name])\n",
    "    next_col = next_col.loc[mask, :]\n",
    "    df = df.join(next_col, on=['entry', 'subentry'])\n",
    "\n",
    "part_df.index.name = 'entry'\n",
    "print(\"Generated!\")\n",
    "print(\"Original Size:\", size/10**6, \"MB\")\n",
    "print(\"Slimmed Size:\", sys.getsizeof(df)/10**6, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Begin Analysis\n",
    "The following cell initializes all the necessary variables to be used in the analysis loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize some debug counting variables\n",
    "These variables keep track of some important data regarding how many particles are ignored, how many data points are ignored, and the number of data points / particles that are ignored for each of the various possible reasons. This way we can keep track of the main reasons why data from certain particles is not being considered.\n",
    "- Move info on nege, highe, non-muon, and the number of bad particles to slimming section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncates a given (multiindexed) dataframe after the first bad datapoint\n",
    "def truncate(df):\n",
    "    df = df.droplevel(level=0)\n",
    "    bad_indices = df.index[(df.dedx_y > 100) | (df.e_y <= 0) | (df.pitch_y < 0.3) | (df.pitch_y > 0.3/np.cos(70*np.pi/180))]\n",
    "    if len(bad_indices) == 0:\n",
    "        return df\n",
    "    \n",
    "    trunc = min(bad_indices)\n",
    "    if trunc < 10:\n",
    "        return df.iloc[:0]\n",
    "    \n",
    "    return df.iloc[:trunc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the delta rays from a given muon (miltiindexed) dataframe\n",
    "def delta_rm(df):\n",
    "    df = df.droplevel(level=0)\n",
    "    \n",
    "    delta_locs, count = deltas(df.dedx_y.to_numpy())\n",
    "    return df.drop(delta_locs, axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_uptime(start, msg=''):\n",
    "    now = time.perf_counter()\n",
    "    t = now-start\n",
    "    print(f'{msg} {int(t//60)}m {t%60:0.1f}s')\n",
    "    return now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(df, part_df):\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    print('Analyzing...', end='')\n",
    "    dxs = df.groupby(level=0).rr_y.diff(periods=1).fillna(df.rr_y)\n",
    "    des = dxs * df.dedx_y / 1000\n",
    "    cum_eloss = des.groupby(level=0).cumsum()\n",
    "    \n",
    "    \n",
    "    data = df[['dedx_y', 'pitch_y']].join(part_df.backtracked_e, on='entry')\n",
    "    data.backtracked_e -= cum_eloss\n",
    "    data.rename(columns={'backtracked_e': 'e_y'}, inplace=True)\n",
    "    tanalyzed = display_uptime(start)\n",
    "    \n",
    "    print('Applying Cuts...', end='')\n",
    "    data = data.groupby(level=0).apply(truncate)\n",
    "    tcut = display_uptime(tanalyzed)\n",
    "    \n",
    "    print('Removing Delta-Rays...', end='')\n",
    "    data = data.groupby(level=0).apply(delta_rm)\n",
    "    tdelta_rm = display_uptime(tcut)\n",
    "    \n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    display_uptime(start, 'Done! Total Analysis Time:')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing... 0m 7.8s\n",
      "Applying Cuts... 0m 29.3s\n",
      "Removing Delta-Rays... 0m 16.6s\n",
      "Done! Total Analysis Time: 0m 53.7s\n"
     ]
    }
   ],
   "source": [
    "data = analyze_data(df, part_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dedx_y</th>\n",
       "      <th>pitch_y</th>\n",
       "      <th>e_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.541412</td>\n",
       "      <td>0.563403</td>\n",
       "      <td>9.336881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.566944</td>\n",
       "      <td>0.563348</td>\n",
       "      <td>9.335584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.129791</td>\n",
       "      <td>0.563345</td>\n",
       "      <td>9.334373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.324910</td>\n",
       "      <td>0.563407</td>\n",
       "      <td>9.333061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.042750</td>\n",
       "      <td>0.563404</td>\n",
       "      <td>9.331923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738653</th>\n",
       "      <td>0.413425</td>\n",
       "      <td>0.753983</td>\n",
       "      <td>6.236037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738654</th>\n",
       "      <td>2.991644</td>\n",
       "      <td>0.753983</td>\n",
       "      <td>6.235998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738655</th>\n",
       "      <td>2.457547</td>\n",
       "      <td>0.754043</td>\n",
       "      <td>6.234173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738656</th>\n",
       "      <td>2.168005</td>\n",
       "      <td>0.754043</td>\n",
       "      <td>6.232259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738657</th>\n",
       "      <td>1.599324</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>6.231318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738658 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dedx_y   pitch_y       e_y\n",
       "0       2.541412  0.563403  9.336881\n",
       "1       2.566944  0.563348  9.335584\n",
       "2       2.129791  0.563345  9.334373\n",
       "3       2.324910  0.563407  9.333061\n",
       "4       2.042750  0.563404  9.331923\n",
       "...          ...       ...       ...\n",
       "738653  0.413425  0.753983  6.236037\n",
       "738654  2.991644  0.753983  6.235998\n",
       "738655  2.457547  0.754043  6.234173\n",
       "738656  2.168005  0.754043  6.232259\n",
       "738657  1.599324  0.753982  6.231318\n",
       "\n",
       "[738658 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
